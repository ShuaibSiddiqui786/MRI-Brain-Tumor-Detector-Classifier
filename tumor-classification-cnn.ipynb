{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system modules\n",
    "import os\n",
    "import itertools\n",
    "from PIL import Image\n",
    "\n",
    "# preprocessing modules\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# deep learning modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to training data directory\n",
    "training_data_path = os.path.normpath(\"brain_tumor_data/Training/\")\n",
    "\n",
    "# initialize lists to store paths of images and their labels\n",
    "img_paths = []\n",
    "labels = []\n",
    "\n",
    "# directories -> lists\n",
    "training_dir = os.listdir(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths and labels of classes and images in training directory\n",
    "for i in training_dir:\n",
    "    class_path = os.path.join(training_data_path, i)\n",
    "    img_list = os.listdir(class_path)\n",
    "\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(class_path, img)\n",
    "        img_paths.append(img_path)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists of img_Paths and their labels into Pandas Series\n",
    "paths = pd.Series(img_paths, name=\"path\")\n",
    "labels = pd.Series(labels, name=\"label\")\n",
    "\n",
    "# concatenate into one Pandas Dataframe\n",
    "train_data = pd.concat([paths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to test data directory\n",
    "testing_data_path = os.path.normpath(\"brain_tumor_data/Testing/\")\n",
    "\n",
    "# initialize lists to store paths of images and their labels\n",
    "img_paths = []\n",
    "labels = []\n",
    "\n",
    "# directories -> lists\n",
    "testing_dir = os.listdir(testing_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths and labels of classes and images in testing directory\n",
    "for i in testing_dir:\n",
    "    class_path = os.path.join(testing_data_path, i)\n",
    "    img_list = os.listdir(class_path)\n",
    "\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(class_path, img)\n",
    "        img_paths.append(img_path)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists of img_Paths and their labels into Pandas Series\n",
    "paths = pd.Series(img_paths, name=\"path\")\n",
    "labels = pd.Series(labels, name=\"label\")\n",
    "\n",
    "# concatenate into one Pandas Dataframe\n",
    "test_data = pd.concat([paths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Test Data into Validation and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test data in half to a validation and test set\n",
    "# shuffled since originally ordered by tumor classification\n",
    "valid_df, test_df = train_test_split(test_data, train_size = 0.5, shuffle = True, random_state = 123)\n",
    "print(\"Test Set shape:\", test_df.shape)\n",
    "print(\"Validation Set shape:\", valid_df.shape)### Split Test Data into Validation and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 20\n",
    "img_size = (224,224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "\n",
    "# initialize generators\n",
    "training_generator = ImageDataGenerator(fill_mode='nearest')\n",
    "validation_generator = ImageDataGenerator()\n",
    "testing_generator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate New Data for Fitting into Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = training_generator.flow_from_dataframe(train_data, x_col = 'path', y_col = 'label', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = validation_generator.flow_from_dataframe(valid_df, x_col = 'path', y_col = 'label', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testing_generator.flow_from_dataframe(test_df, x_col = 'path', y_col = 'label', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = False, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Batch from Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels and their indices in a dictionary\n",
    "label_index = train.class_indices\n",
    "label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label list\n",
    "keys = list(label_index.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample batch\n",
    "imgs, labels = next(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the batch\n",
    "plt.figure(figsize= (20, 20))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i +1)\n",
    "    im = imgs[i]/255\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    index = np.argmax(labels[i])\n",
    "    label = keys[index]\n",
    "    plt.title(label, size=40, color = 'black')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Batch from Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same label_index and keys\n",
    "\n",
    "# get a sample batch\n",
    "imgs, labels = next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the batch\n",
    "plt.figure(figsize= (20, 20))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i +1)\n",
    "    im = imgs[i]/255\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    index = np.argmax(labels[i])\n",
    "    label = keys[index]\n",
    "    plt.title(label, size=40, color = 'black')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Batch from Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same label_index and keys\n",
    "\n",
    "# get a sample batch\n",
    "imgs, labels = next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the batch\n",
    "plt.figure(figsize= (20, 20))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i +1)\n",
    "    im = imgs[i]/255\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    index = np.argmax(labels[i])\n",
    "    label = keys[index]\n",
    "    plt.title(label, size=40, color = 'black')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for CNN\n",
    "batch_size = 20\n",
    "img_size = (224,224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of unique classes to set the number of neurons in the final layer.\n",
    "# each neuron represents the probability of a corresponding class\n",
    "num_classes = len(list(train.class_indices.keys()))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = Sequential([\n",
    "    Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'elu', input_shape = img_shape),\n",
    "    Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'elu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(256, activation = 'elu'),\n",
    "    Dense(128, activation = 'elu'),\n",
    "    Dense(64, activation = 'elu'),\n",
    "    Dense(32, activation = 'elu'),\n",
    "    Dense(num_classes, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "CNN.compile(Adamax(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "history = CNN.fit(x=train, epochs=epochs, verbose=1, validation_data=valid, shuffle=False)\n",
    "# 19hr 30min to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy and loss on training data\n",
    "training_acc = history.history['accuracy']\n",
    "training_loss = history.history['loss']\n",
    "\n",
    "# accuracy and loss on validation data\n",
    "validation_acc = history.history['val_accuracy']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# highest value of validation accuracy, and index of where it happened\n",
    "index_acc = np.argmax(validation_acc)\n",
    "high_validation_acc = validation_acc[index_acc]\n",
    "\n",
    "# lowed value of validation accuracy, and index of where it happened\n",
    "index_loss = np.argmin(validation_loss)\n",
    "low_validation_loss = validation_loss[index_loss]\n",
    "\n",
    "# number of epochs based on length of training accuracy values\n",
    "epochs =[]\n",
    "for i in range(len(training_acc)):\n",
    "    epochs.append (i+1)\n",
    "\n",
    "# define best epoch\n",
    "best_acc = f'Best Epoch ={str(index_acc +1)}'\n",
    "best_loss = f'Best Epoch ={str(index_loss+1)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 8))\n",
    "plt.style.use('bmh')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, training_acc, \"b\", label = \"Training Accuarcy\")\n",
    "plt.plot(epochs, validation_acc, \"r\", label = \"Validation Accuarcy\")\n",
    "plt.scatter(index_acc+1, high_validation_acc, s= 150, color = 'green', label = best_acc)\n",
    "\n",
    "plt.title(\"Accuracy: Training vs Valid\")\n",
    "plt. xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, training_loss, \"b\", label = \"Training Loss\")\n",
    "plt.plot(epochs, validation_loss, \"r\", label = \"Validation Loss\")\n",
    "plt.scatter(index_loss+1, low_validation_loss, s= 150, color = 'green', label = best_loss)\n",
    "\n",
    "plt.title(\"Loss: Training vs Validation\")\n",
    "plt. xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = CNN.evaluate(train, verbose = 0)\n",
    "valid_score = CNN.evaluate(valid, verbose = 0)\n",
    "test_score = CNN.evaluate(test, verbose = 0)\n",
    "\n",
    "print('____________________________________________________________________')\n",
    "print(f'Train Scores:        | Validation Scores:    | Test Scores:')\n",
    "print(f'    Accuracy: {train_score[1]:.4f} |     Accuracy: {valid_score[1]:.4f}  |     Accuracy: {test_score[1]:.4f}')\n",
    "print(f'    Loss: {train_score[0]:.4f}     |     Loss: {valid_score[0]:.4f}      |     Loss: {test_score[0]:.4f}')\n",
    "print('_____________________|_______________________|______________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('____________________________________________________________________')\n",
    "print(f'Train Scores:        | Validation Scores:    | Test Scores:')\n",
    "print(f'    Accuracy: {train_score[1]:.4f} |     Accuracy: {valid_score[1]:.4f}  |     Accuracy: {test_score[1]:.4f}')\n",
    "print(f'    Loss: {train_score[0]:.4f}     |     Loss: {valid_score[0]:.4f}      |     Loss: {test_score[0]:.4f}')\n",
    "print('_____________________|_______________________|______________________')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CNN.predict(test)\n",
    "y_pred = np.argmax(predictions, axis = 1)\n",
    "\n",
    "print(\"\\nPredictions (Probabilities of Each Class):\\n\", predictions[:5])  # show first 5 predictions\n",
    "print(\"\\nPredicted Classes (Highest Probable Class):\\n\", y_pred[:5])  # show first 5 predicted classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use n. of keys of  Class indices to greate confusion matrix\n",
    "Test_cl_ind = test.class_indices\n",
    " \n",
    "# Get Keys\n",
    "classes = list(Test_cl_ind.keys())\n",
    "\n",
    "cm = confusion_matrix(test.classes, y_pred)\n",
    "\n",
    "plt.figure(figsize =(8, 8))\n",
    "plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes,rotation = 45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    if cm[i, j] == 0:\n",
    "        text_color = 'black'  # black for zero values\n",
    "    elif i == j:\n",
    "        text_color = 'white'  # white for diagonal (correct classifications)\n",
    "    else:\n",
    "        text_color = 'red'    # red for misclassifications\n",
    "\n",
    "    plt.text(j, i, cm[i, j],\n",
    "             horizontalalignment='center',\n",
    "             verticalalignment='center',\n",
    "             color=text_color)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report (Precision, Recall, F1-Score, Accuracy Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test.classes, y_pred, target_names = classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.save('models/brain_tumor_cnn_classifier.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model (Test Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "CNN = tf.keras.models.load_model(\"models/brain_tumor_cnn_classifier.keras\", compile=False)\n",
    "CNN.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001), \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports if we loaded this independently (inside web app)\n",
    "from PIL import Image # instead of openCV since simpler tasks\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# paths to images from each class\n",
    "image_paths = {\n",
    "    'glioma': 'brain_tumor_data/Testing/glioma/Te-gl_0025.jpg',\n",
    "    'meningioma': 'brain_tumor_data/Testing/meningioma/Te-me_0010.jpg',\n",
    "    'no tumor': 'brain_tumor_data/Testing/notumor/\\Te-no_0010.jpg',\n",
    "    'pituitary': 'brain_tumor_data/Testing/pituitary/Te-pi_0040.jpg'\n",
    "}\n",
    "\n",
    "# initializations\n",
    "plt.figure(figsize=(10, 8))\n",
    "class_labels = ['glioma', 'meningioma', 'no tumor', 'pituitary']\n",
    "\n",
    "for i, (label, path) in enumerate(image_paths.items()):\n",
    "    img = Image.open(path)\n",
    "    img_resized = img.resize((224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # expand dimensions to fit model input\n",
    "\n",
    "    # predict and process the results\n",
    "    predictions = CNN.predict(img_array, verbose=0) # verbose at 0 to prevent status plot\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    predicted_class = class_labels[np.argmax(score)]\n",
    "\n",
    "    # plot\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # title\n",
    "    actual_text = f'Actual: {label}'\n",
    "    predicted_text = f'Predicted: {predicted_class}'\n",
    "    probability_text = f'Probability (vs other 3 classes): {np.max(score):.2f}'\n",
    "    \n",
    "    # title formatting\n",
    "    spacing = 0.02\n",
    "    plt.text(0.5, 1.15 + 2*spacing, actual_text, ha='center', va='bottom', transform=plt.gca().transAxes, fontsize='medium', color='black')\n",
    "    plt.text(0.5, 1.10 + spacing, predicted_text, ha='center', va='bottom', transform=plt.gca().transAxes, fontsize='medium', color='green')\n",
    "    plt.text(0.5, 1.05, probability_text, ha='center', va='bottom', transform=plt.gca().transAxes, fontsize='medium', color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
